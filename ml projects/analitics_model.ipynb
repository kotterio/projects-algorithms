{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733a854",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a2bf3",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import sparse\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9568f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Colab Notebooks/avarar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b8342",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771213b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import sparse\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d6295",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip -q install -U sentence-transformers catboost pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip -q install -U fastparquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c37f7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TARGET = \"item_contact\"\n",
    "cols = [\n",
    "    \"query_id\",\"item_id\",\"query_text\",\"item_title\",\"item_description\",\n",
    "    \"query_cat\",\"query_mcat\",\"query_loc\",\"item_cat_id\",\"item_mcat_id\",\"item_loc\",\n",
    "    \"price\",\"item_query_click_conv\",\n",
    "]\n",
    "\n",
    "train = pd.read_parquet(\"train-dset.parquet\", columns=cols + [TARGET], engine=\"fastparquet\")\n",
    "test  = pd.read_parquet(\"test-dset-small.parquet\", columns=cols, engine=\"fastparquet\")\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe4363",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "text_cols = [\"query_text\",\"item_title\",\"item_description\"]\n",
    "cat_cols  = [\"query_cat\",\"query_mcat\",\"query_loc\",\"item_cat_id\",\"item_mcat_id\",\"item_loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7d6b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "GROUP  = \"query_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945dd10f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3e300",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    for c in text_cols:\n",
    "        df[c] = df[c].fillna(\"\").astype(str)\n",
    "\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].fillna(\"NA\").astype(str)\n",
    "\n",
    "    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\").fillna(0).astype(np.float32)\n",
    "    df[\"item_query_click_conv\"] = pd.to_numeric(df[\"item_query_click_conv\"], errors=\"coerce\")\n",
    "    df[\"conv_missing\"] = (df[\"item_query_click_conv\"] < 0).astype(np.int8)\n",
    "    df.loc[df[\"item_query_click_conv\"] < 0, \"item_query_click_conv\"] = np.nan\n",
    "    med = df[\"item_query_click_conv\"].median()\n",
    "    df[\"item_query_click_conv\"] = df[\"item_query_click_conv\"].fillna(med if np.isfinite(med) else 0).astype(np.float32)\n",
    "    df[\"cat_match\"]  = (df[\"query_cat\"]  == df[\"item_cat_id\"]).astype(np.int8)\n",
    "    df[\"mcat_match\"] = (df[\"query_mcat\"] == df[\"item_mcat_id\"]).astype(np.int8)\n",
    "    df[\"loc_match\"]  = (df[\"query_loc\"]  == df[\"item_loc\"]).astype(np.int8)\n",
    "    df[\"log_price\"] = np.log1p(df[\"price\"].clip(lower=0)).astype(np.float32)\n",
    "    g = df.groupby(GROUP)[\"price\"]\n",
    "    df[\"price_rank_pct\"] = g.rank(pct=True).astype(np.float32)\n",
    "\n",
    "    mu = g.transform(\"mean\").astype(np.float32)\n",
    "    sd = g.transform(\"std\").replace(0, np.nan).astype(np.float32)\n",
    "    df[\"price_z\"] = ((df[\"price\"] - mu) / sd).fillna(0).astype(np.float32)\n",
    "    df[\"q_len\"] = df[\"query_text\"].str.len().astype(np.int32)\n",
    "    df[\"t_len\"] = df[\"item_title\"].str.len().astype(np.int32)\n",
    "    df[\"d_len\"] = df[\"item_description\"].str.len().astype(np.int32)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5eab7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train = prepare(train)\n",
    "test  = prepare(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a191f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "TARGET_SHARE = 0.80\n",
    "\n",
    "vc = train[\"item_id\"].value_counts()\n",
    "cum_share = vc.cumsum() / len(train)\n",
    "K = int(np.searchsorted(cum_share.values, TARGET_SHARE) + 1)\n",
    "\n",
    "print(\"K_for_share\", TARGET_SHARE, \"=\", K)\n",
    "print(\"topK covers:\", float(cum_share.values[K-1]))\n",
    "\n",
    "freq_items = vc.head(K).index.values\n",
    "pos_items = train.loc[train[TARGET] == 1, \"item_id\"].unique()\n",
    "\n",
    "keep_items = np.unique(np.concatenate([freq_items, pos_items]))\n",
    "print(\"keep_items unique:\", len(keep_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e647bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch, os\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pop_model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "\n",
    "CACHE_DIR = \"/content/drive/MyDrive/avito_emb_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba0ac1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DESC_MAX_CHARS = 300\n",
    "q_all = pd.concat([\n",
    "    train[[GROUP, \"query_text\"]],\n",
    "    test[[GROUP, \"query_text\"]],\n",
    "], axis=0).drop_duplicates(GROUP).reset_index(drop=True)\n",
    "\n",
    "TOPK_FREQ = 1_200_000\n",
    "TOPK_CONV = 300_000\n",
    "\n",
    "pos_items = train.loc[train[TARGET] == 1, \"item_id\"].unique()\n",
    "freq_items = train[\"item_id\"].value_counts().head(TOPK_FREQ).index.values\n",
    "conv_items = (\n",
    "    train.loc[train[\"item_query_click_conv\"].fillna(-1) >= 0, \"item_id\"]\n",
    "    .value_counts().head(TOPK_CONV).index.values\n",
    ")\n",
    "\n",
    "keep_items = np.unique(np.concatenate([pos_items, freq_items, conv_items]))\n",
    "\n",
    "i_all = pd.concat([\n",
    "    test[[\"item_id\",\"item_title\",\"item_description\"]],\n",
    "    train.loc[train[\"item_id\"].isin(keep_items), [\"item_id\",\"item_title\",\"item_description\"]],\n",
    "], axis=0).drop_duplicates(\"item_id\").reset_index(drop=True)\n",
    "\n",
    "print(\"i_all unique items:\", len(i_all))\n",
    "i_all[\"item_text\"] = (\n",
    "    i_all[\"item_title\"].astype(str)\n",
    "    + \" [SEP] \"\n",
    "    + i_all[\"item_description\"].astype(str).str.slice(0, DESC_MAX_CHARS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd721f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def encode_to_memmap_series(text_series: pd.Series, out_path, batch_size=128, dtype=np.float16):\n",
    "    n = len(text_series)\n",
    "    meta_path = out_path + \".meta.npy\"\n",
    "    if os.path.exists(out_path) and os.path.exists(meta_path):\n",
    "        dim = int(np.load(meta_path))\n",
    "        return np.memmap(out_path, mode=\"r\", dtype=dtype, shape=(n, dim))\n",
    "\n",
    "    b0 = min(batch_size, n)\n",
    "    emb0 = pop_model.encode(\n",
    "        text_series.iloc[:b0].tolist(),\n",
    "        batch_size=b0,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    dim = emb0.shape[1]\n",
    "    np.save(meta_path, np.array(dim, dtype=np.int32))\n",
    "\n",
    "    mm = np.memmap(out_path, mode=\"w+\", dtype=dtype, shape=(n, dim))\n",
    "    mm[:b0] = emb0.astype(dtype)\n",
    "\n",
    "    start = b0\n",
    "    while start < n:\n",
    "        end = min(start + batch_size, n)\n",
    "        emb = pop_model.encode(\n",
    "            text_series.iloc[start:end].tolist(),\n",
    "            batch_size=batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "        mm[start:end] = emb.astype(dtype)\n",
    "        start = end\n",
    "\n",
    "    mm.flush()\n",
    "    return np.memmap(out_path, mode=\"r\", dtype=dtype, shape=(n, dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf55331",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_TAG = MODEL_NAME.split(\"/\")[-1]\n",
    "Q_VER = \"v6\"\n",
    "q_path = os.path.join(CACHE_DIR, f\"q_emb_{MODEL_TAG}_{Q_VER}.f16.mmp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6e4ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "I_VER = \"v10\"\n",
    "i_path = os.path.join(CACHE_DIR, f\"i_emb_{MODEL_TAG}_desc{DESC_MAX_CHARS}_n{len(i_all)}_{I_VER}.f16.mmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af0237",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "q_emb = encode_to_memmap_series(q_all[\"query_text\"], q_path, batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3f793",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "i_emb = encode_to_memmap_series(i_all[\"item_text\"],  i_path, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abf5c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(q_emb.shape, i_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e5cf2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if \"q_idx\" not in q_all.columns:\n",
    "    q_all = q_all.copy()\n",
    "    q_all[\"q_idx\"] = np.arange(len(q_all), dtype=np.int32)\n",
    "\n",
    "if \"i_idx\" not in i_all.columns:\n",
    "    i_all = i_all.copy()\n",
    "    i_all[\"i_idx\"] = np.arange(len(i_all), dtype=np.int32)\n",
    "\n",
    "\n",
    "train = train.merge(q_all[[GROUP, \"q_idx\"]], on=GROUP, how=\"left\")\n",
    "test  = test.merge(q_all[[GROUP, \"q_idx\"]], on=GROUP, how=\"left\")\n",
    "\n",
    "train = train.merge(i_all[[\"item_id\", \"i_idx\"]], on=\"item_id\", how=\"left\")\n",
    "test  = test.merge(i_all[[\"item_id\", \"i_idx\"]], on=\"item_id\", how=\"left\")\n",
    "print([c for c in train.columns if \"i_idx\" in c])\n",
    "print([c for c in i_all.columns if \"i_idx\" in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe9315",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train[\"has_sim\"] = train[\"i_idx\"].notna()\n",
    "test[\"has_sim\"]  = test[\"i_idx\"].notna()\n",
    "\n",
    "train[\"sim_q_item\"] = 0.0\n",
    "test[\"sim_q_item\"]  = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202042e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "missing_q = train[\"q_idx\"].isna().sum()\n",
    "if missing_q:\n",
    "    print(\"train rows without q_emb:\", missing_q, \"=> dropping them\")\n",
    "    train = train[train[\"q_idx\"].notna()].copy()\n",
    "\n",
    "missing_q_test = test[\"q_idx\"].isna().sum()\n",
    "if missing_q_test:\n",
    "    print(\"test rows without q_emb:\", missing_q_test, \"=> dropping them\")\n",
    "    test = test[test[\"q_idx\"].notna()].copy()\n",
    "train[\"q_idx\"] = train[\"q_idx\"].astype(np.int32)\n",
    "test[\"q_idx\"]  = test[\"q_idx\"].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b544998",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_sim_feature(df: pd.DataFrame, chunk_size=200_000) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "    sims = np.empty(n, dtype=np.float32)\n",
    "\n",
    "    q_idx = df[\"q_idx\"].to_numpy(np.int32)\n",
    "    i_idx = df[\"i_idx\"].to_numpy(np.int32)\n",
    "\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "\n",
    "        Q = np.array(q_emb[q_idx[start:end]], dtype=np.float32)\n",
    "        I = np.array(i_emb[i_idx[start:end]], dtype=np.float32)\n",
    "\n",
    "        sims[start:end] = np.einsum(\"ij,ij->i\", Q, I)\n",
    "\n",
    "        if start == 0:\n",
    "            print(\"first chunk sim stats:\", sims[start:end].min(), sims[start:end].mean(), sims[start:end].max())\n",
    "\n",
    "    df[\"sim_q_item\"] = sims\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb649060",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_sim = train[train[\"has_sim\"] & train[\"q_idx\"].notna()].copy()\n",
    "test_sim  = test[test[\"has_sim\"] & test[\"q_idx\"].notna()].copy()\n",
    "\n",
    "train_sim[\"q_idx\"] = train_sim[\"q_idx\"].astype(np.int32)\n",
    "train_sim[\"i_idx\"] = train_sim[\"i_idx\"].astype(np.int32)\n",
    "test_sim[\"q_idx\"]  = test_sim[\"q_idx\"].astype(np.int32)\n",
    "test_sim[\"i_idx\"]  = test_sim[\"i_idx\"].astype(np.int32)\n",
    "\n",
    "train_sim = add_sim_feature(train_sim, chunk_size=200_000)\n",
    "test_sim  = add_sim_feature(test_sim,  chunk_size=200_000)\n",
    "train.loc[train_sim.index, \"sim_q_item\"] = train_sim[\"sim_q_item\"].values\n",
    "test.loc[test_sim.index, \"sim_q_item\"]   = test_sim[\"sim_q_item\"].values\n",
    "train.loc[~train[\"has_sim\"], \"sim_q_item\"] = -2.0\n",
    "test.loc[~test[\"has_sim\"],  \"sim_q_item\"]  = -2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60935d73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRanker, Pool\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "features = cat_cols + [\n",
    "    \"price\",\"log_price\",\"price_rank_pct\",\"price_z\",\n",
    "    \"item_query_click_conv\",\"conv_missing\",\n",
    "    \"cat_match\",\"mcat_match\",\"loc_match\",\n",
    "    \"q_len\",\"t_len\",\"d_len\",\n",
    "    \"has_sim\",\n",
    "    \"sim_q_item\",\n",
    "]\n",
    "\n",
    "train = train.sort_values([GROUP, \"item_id\"]).reset_index(drop=True)\n",
    "\n",
    "X = train[features]\n",
    "y = train[TARGET].astype(np.float32).values\n",
    "qid = train[GROUP].values\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "tr_idx, va_idx = next(gkf.split(X, y, groups=qid))\n",
    "tr_idx = np.sort(tr_idx)\n",
    "va_idx = np.sort(va_idx)\n",
    "\n",
    "train_pool = Pool(\n",
    "    X.iloc[tr_idx], label=y[tr_idx], group_id=qid[tr_idx],\n",
    "    cat_features=cat_cols\n",
    ")\n",
    "valid_pool = Pool(\n",
    "    X.iloc[va_idx], label=y[va_idx], group_id=qid[va_idx],\n",
    "    cat_features=cat_cols\n",
    ")\n",
    "\n",
    "params = dict(\n",
    "    loss_function=\"YetiRank\",\n",
    "    eval_metric=\"NDCG:top=10\",\n",
    "    iterations=2000,\n",
    "    learning_rate=0.04,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=6.0,\n",
    "    random_strength=0.8,\n",
    "    verbose=50,\n",
    "    task_type=\"GPU\" if torch.cuda.is_available() else \"CPU\",\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=100,\n",
    "    metric_period=50,\n",
    "    bootstrap_type=\"Bernoulli\",\n",
    "    subsample=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a4687",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cb_model = CatBoostRanker(**params, random_seed=42)\n",
    "cb_model.fit(train_pool, eval_set=valid_pool, use_best_model=True, plot=True)\n",
    "best_iter = cb_model.get_best_iteration()\n",
    "print(\"best_iter:\", best_iter)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
